# Capstone_project-1_PG
Metaheuristic Hyperparameter Tuning for Mitigating Hallucinations in LLM
For experimental assessment, evaluation was conducted us-
ing benchmark datasets obtained from the Hugging Face
repository, namely the HaluEval and SummEval datasets.
These datasets were merged to form a unified corpus to
enable a collective and comprehensive evaluation of hallu-
cination behavior across diverse natural language processing
tasks.The combined dataset contains over 36107 examples,
each consisting of a reference response, a corresponding
output generated by a large language model (LLM), and
associated factuality or hallucination labels. Both HaluEval
and SummEval provide fine-grained hallucination annota-
tions spanning a wide range of domains. The complemen-
tary nature of these datasets supports variation in linguistic
styles and hallucination intensity. The unified dataset was
partitioned into training (70%), validation (15%), and testing
(15%) subsets, ensuring a balanced distribution of halluci-
nated and non-hallucinated samples across all splits. The
training and validation sets were utilized during the optimiza-
tion feedback process, while the test set was reserved exclu-
sively for final evaluation to ensure unbiased performance
assessmen
